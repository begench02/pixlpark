Архитектура: Feature Sliced Design [FSD] - именно для этого задания возможно это необязательное усложнение, но все же.

<mark>/entries/story/story.store.ts:</mark>
У стора есть три состояния:</br>
* <b>'IDLE'</b> - все хорошо, данные актуальные, если произошел запрос на получение stories когда store находится в состоянии 'IDLE', то возвращаем хранящиеся в сторе данные (случай, когда пользователь зашел на stories/:id и перешел обратно)
* <b>'STALE'</b> - наши данные не актуальные (при прошествии 1 минуты или если пользователь нажал на обновления stories), необходимо заново сделать запрос и получить более актуальные данные, но пока данные не получены, показываем старые данные
* <b>'FETCHING'</b> - Store принимает это состояние при начальной загрузке данных, показываем loader

<code>fetchStories()</code> - Главная проблема в том, что нам надо сделать 100 запросов на 
получение новостей, первое что приходит в голову это виртуализация данных, то есть делать запросы только при скролле вниз, но необходимая нам сортировка по времени не позволяет нам это сделать. Если даже мы постараемся сделать это как-то динамически, stories на сайте будут прыгать, поэтому сначала все отсортировываем и только потом показываем. Также я специально отказался от использования await-ов и написал на промисах для максимальной параллельности запросов. В браузерах есть лимит на количество параллельных запросов, в HTTP/1.1 (у hacker-news сервер работает на HTTP/1.1) для браузера Chrome это 6 запросов единовременно, остальные запросы ждут завершения предыдущих, что значит, что если далее будет необходимость делать супер-важный запросы на странице "/stories", то нужно его делать до начала 100 запросов, иначе наш супер-важный запрос будет ждать завершения 95-и запросов

<code>getStoryById()</code> - было несколько идей насчет реализации этого метода:
1. Использовать "date" вместо "id" для уникальной идентификации, так как новости по требованию обязательно должны быть отсортированы по дате.
Плюсы: Позволит нам сократить время поиска с линейного O(n) на логарифмический O(logn) используя бинарный поиск
Минусы: Если несколько сервером и они работают с Network Time Protocol (NTP), то есть вероятность назначение разным новостям одного unix времени.
2. Использовать new Map() и хранить отсортированные новости не в массиве, а в хэш таблице:
Плюсы: поиск новости за константное время - O(1)
Минусы: И так долгий First Contentful Paint (FCP), еще добавляем линейное время на итерацию по отсортированному массиву для создание хэш таблицы

<code>getCommentsByStoryId()</code> - можно оставить его в состоянии компоненты, но из-за обилия логики и сильного сцепления с новостями решил вынести его в storyStore + можно хранить историю комментариев, учитывая, что есть ограничение на 100 новостей, можно не сильно заморачиваться над дополнительной памятью для их хранения, не будь у нас ограничения, можно было бы реализовать какой-то алгоритм вытеснения, например Least Recently Used или Least Frequently Used. Также не будут храниться вложенные комментарии, из-за неизвестности глубины вложенности, будут храниться только комментарии самого высокого уровня